#!/usr/bin/env python3
"""
ğŸš€ Site Builder CLI Tool
Ø§Ø¨Ø²Ø§Ø± Ø®Ø· ÙØ±Ù…Ø§Ù† Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ØŒ ØªØ­Ù„ÛŒÙ„ Ùˆ Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª
"""

import argparse
import sys
import os
import json
import subprocess
from pathlib import Path

class SiteBuilderCLI:
    def __init__(self):
        self.version = "0.1.0"
        self.description = "Ø§Ø¨Ø²Ø§Ø± Ú©Ø§Ù…Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª"
    
    def extract(self, url, output_path, options=None):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø§Ù„Ø¨ Ø§Ø² URL"""
        print(f"ğŸ” Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø²: {url}")
        print(f"ğŸ“ Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ: {output_path}")
        
        try:
            # Ø§Ø¬Ø±Ø§ÛŒ Node.js extractor
            extractor_path = Path(__file__).parent / "extractor" / "puppeteer.js"
            
            if not extractor_path.exists():
                print("âŒ ÙØ§ÛŒÙ„ extractor ÛŒØ§ÙØª Ù†Ø´Ø¯!")
                return False
            
            cmd = [
                "node", 
                str(extractor_path),
                url,
                output_path
            ]
            
            if options and options.get('headless'):
                cmd.append('--headless')
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
                return True
            else:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")
            return False
    
    def analyze(self, input_path):
        """ØªØ­Ù„ÛŒÙ„ Ù‚Ø§Ù„Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡"""
        print(f"ğŸ“Š ØªØ­Ù„ÛŒÙ„ Ù‚Ø§Ù„Ø¨ Ø¯Ø±: {input_path}")
        
        try:
            input_path = Path(input_path)
            
            if not input_path.exists():
                print("âŒ Ù…Ø³ÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯!")
                return False
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            files = {
                'html': input_path / 'index.html',
                'css': input_path / 'styles.css',
                'js': input_path / 'scripts.js',
                'metadata': input_path / 'metadata.json'
            }
            
            analysis = {
                'path': str(input_path),
                'files': {},
                'stats': {}
            }
            
            for file_type, file_path in files.items():
                if file_path.exists():
                    size = file_path.stat().st_size
                    analysis['files'][file_type] = {
                        'exists': True,
                        'size': size,
                        'size_kb': round(size / 1024, 2)
                    }
                else:
                    analysis['files'][file_type] = {'exists': False}
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† metadata Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯
            if files['metadata'].exists():
                with open(files['metadata'], 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                    analysis['metadata'] = metadata
            
            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬
            print("\nğŸ“‹ Ù†ØªØ§ÛŒØ¬ ØªØ­Ù„ÛŒÙ„:")
            print(f"ğŸ“ Ù…Ø³ÛŒØ±: {analysis['path']}")
            
            for file_type, info in analysis['files'].items():
                if info['exists']:
                    print(f"âœ… {file_type.upper()}: {info['size_kb']} KB")
                else:
                    print(f"âŒ {file_type.upper()}: Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª")
            
            if 'metadata' in analysis:
                meta = analysis['metadata']
                print(f"\nğŸ“Š Ø¢Ù…Ø§Ø±:")
                print(f"  - Ø¹Ù†ÙˆØ§Ù†: {meta.get('title', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
                print(f"  - URL: {meta.get('url', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
                print(f"  - ØªØ§Ø±ÛŒØ® Ø§Ø³ØªØ®Ø±Ø§Ø¬: {meta.get('extractedAt', 'Ù†Ø§Ù…Ø´Ø®Øµ')}")
                print(f"  - ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³ØªØ§ÛŒÙ„â€ŒÙ‡Ø§: {meta.get('styles', 0)}")
                print(f"  - ØªØ¹Ø¯Ø§Ø¯ Ø§Ø³Ú©Ø±ÛŒÙ¾Øªâ€ŒÙ‡Ø§: {meta.get('scripts', 0)}")
                print(f"  - ØªØ¹Ø¯Ø§Ø¯ ØªØµØ§ÙˆÛŒØ±: {meta.get('images', 0)}")
                print(f"  - ØªØ¹Ø¯Ø§Ø¯ ÙÙˆÙ†Øªâ€ŒÙ‡Ø§: {meta.get('fonts', 0)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„: {e}")
            return False
    
    def build(self, input_path, output_path, options=None):
        """Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª Ø§Ø² Ù‚Ø§Ù„Ø¨"""
        print(f"ğŸ—ï¸ Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª Ø§Ø²: {input_path}")
        print(f"ğŸ“ Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ: {output_path}")
        
        try:
            input_path = Path(input_path)
            output_path = Path(output_path)
            
            if not input_path.exists():
                print("âŒ Ù…Ø³ÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯!")
                return False
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø®Ø±ÙˆØ¬ÛŒ
            output_path.mkdir(parents=True, exist_ok=True)
            
            # Ú©Ù¾ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
            files_to_copy = ['index.html', 'styles.css', 'scripts.js']
            
            for file_name in files_to_copy:
                src_file = input_path / file_name
                dst_file = output_path / file_name
                
                if src_file.exists():
                    import shutil
                    shutil.copy2(src_file, dst_file)
                    print(f"âœ… Ú©Ù¾ÛŒ Ø´Ø¯: {file_name}")
                else:
                    print(f"âš ï¸ ÙØ§ÛŒÙ„ ÛŒØ§ÙØª Ù†Ø´Ø¯: {file_name}")
            
            # Ú©Ù¾ÛŒ ØªØµØ§ÙˆÛŒØ± Ùˆ ÙÙˆÙ†Øªâ€ŒÙ‡Ø§
            for asset_dir in ['images', 'fonts']:
                src_assets = input_path / asset_dir
                dst_assets = output_path / asset_dir
                
                if src_assets.exists():
                    import shutil
                    shutil.copytree(src_assets, dst_assets, dirs_exist_ok=True)
                    print(f"âœ… Ú©Ù¾ÛŒ Ø´Ø¯: {asset_dir}/")
            
            # Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ
            self._create_additional_files(output_path, options)
            
            print("âœ… Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª Ú©Ø§Ù…Ù„ Ø´Ø¯!")
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª: {e}")
            return False
    
    def _create_additional_files(self, output_path, options=None):
        """Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ"""
        # robots.txt
        robots_content = """User-agent: *
Allow: /
Sitemap: /sitemap.xml
"""
        with open(output_path / 'robots.txt', 'w', encoding='utf-8') as f:
            f.write(robots_content)
        
        # sitemap.xml
        sitemap_content = """<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
    <url>
        <loc>/</loc>
        <lastmod>2024-01-01</lastmod>
        <changefreq>weekly</changefreq>
        <priority>1.0</priority>
    </url>
</urlset>
"""
        with open(output_path / 'sitemap.xml', 'w', encoding='utf-8') as f:
            f.write(sitemap_content)
        
        print("âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯Ù†Ø¯")

def main():
    parser = argparse.ArgumentParser(
        description="ğŸš€ Site Builder CLI - Ø§Ø¨Ø²Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Ù…Ø«Ø§Ù„â€ŒÙ‡Ø§:
  sitebuilder-cli extract https://example.com ./output
  sitebuilder-cli analyze ./output
  sitebuilder-cli build ./output ./final_site
  sitebuilder-cli extract https://example.com ./output --headless
        """
    )
    
    parser.add_argument('--version', action='version', version='%(prog)s 0.1.0')
    
    subparsers = parser.add_subparsers(dest='command', help='Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…ÙˆØ¬ÙˆØ¯')
    
    # Ø¯Ø³ØªÙˆØ± extract
    extract_parser = subparsers.add_parser('extract', help='Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø§Ù„Ø¨ Ø§Ø² URL')
    extract_parser.add_argument('url', help='URL Ø³Ø§ÛŒØª Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬')
    extract_parser.add_argument('output', help='Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ')
    extract_parser.add_argument('--headless', action='store_true', help='Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø¯ÙˆÙ† Ù†Ù…Ø§ÛŒØ´ Ù…Ø±ÙˆØ±Ú¯Ø±')
    
    # Ø¯Ø³ØªÙˆØ± analyze
    analyze_parser = subparsers.add_parser('analyze', help='ØªØ­Ù„ÛŒÙ„ Ù‚Ø§Ù„Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡')
    analyze_parser.add_argument('input', help='Ù…Ø³ÛŒØ± Ù‚Ø§Ù„Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡')
    
    # Ø¯Ø³ØªÙˆØ± build
    build_parser = subparsers.add_parser('build', help='Ø³Ø§Ø®Øª Ø³Ø§ÛŒØª Ø§Ø² Ù‚Ø§Ù„Ø¨')
    build_parser.add_argument('input', help='Ù…Ø³ÛŒØ± Ù‚Ø§Ù„Ø¨ ÙˆØ±ÙˆØ¯ÛŒ')
    build_parser.add_argument('output', help='Ù…Ø³ÛŒØ± Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    cli = SiteBuilderCLI()
    
    if args.command == 'extract':
        options = {'headless': args.headless} if hasattr(args, 'headless') else None
        success = cli.extract(args.url, args.output, options)
    elif args.command == 'analyze':
        success = cli.analyze(args.input)
    elif args.command == 'build':
        success = cli.build(args.input, args.output)
    else:
        print("âŒ Ø¯Ø³ØªÙˆØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø±!")
        success = False
    
    sys.exit(0 if success else 1)

if __name__ == '__main__':
    main()
